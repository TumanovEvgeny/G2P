{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grapheme to Phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Masking, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### reading the train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Id            Word                  Transcription\n",
      "0  1       KNOXVILLE                N AA K S V IH L\n",
      "1  2      MOVIEGOING           M UW V IY G OW IH NG\n",
      "2  3  PHOTOSYNTHESIS  F OW T OW S IH N TH AH S IH S\n",
      "3  4           DELIO                   D EY L IY OW\n",
      "4  5        SWIVELED                S W IH V AH L D\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', dtype={'Word': 'str', 'Transcription': 'str', 'Id': 'str'})\n",
    "print(train.head())\n",
    "train.dropna(inplace=True)\n",
    "X_raw, y_raw, s2id = train.Word.head(1000), train.Transcription.head(1000), train.Id.head(1000)\n",
    "X_raw, y_raw, s2id = np.array(X_raw), np.array(y_raw), np.array(s2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phoneme_data = pd.read_csv('phones.txt', sep = ' ')\n",
    "phoneme_data.head()\n",
    "phoneme_enc = defaultdict()\n",
    "phoneme_dec = defaultdict()\n",
    "for ph, code in zip(phoneme_data.phoneme, phoneme_data.code):\n",
    "    phoneme_enc[ph] = code\n",
    "    phoneme_dec[code] = ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_enc['AA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_WORD_LEN = max(map(len, X_raw)) + 2\n",
    "x_preproc = lambda x: ''.join(['@', x, '#' * (MAX_WORD_LEN - 2 - len(x))])[::-1]\n",
    "X_raw = map(x_preproc, X_raw)\n",
    "\n",
    "y_raw = map(lambda z: ''.join(map(lambda zz: phoneme_enc[zz], z.strip().split(' '))), y_raw)\n",
    "MAX_PHONE_LEN = max(map(len, y_raw)) + 2\n",
    "y_preproc = lambda y: ''.join(['$', y, '%' * (MAX_PHONE_LEN - 2 - len(y))])\n",
    "y_raw = map(y_preproc, y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['########################ELLIVXONK@',\n",
       " '#######################GNIOGEIVOM@',\n",
       " '###################SISEHTNYSOTOHP@',\n",
       " '############################OILED@']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$watCIqu%%%%%%%%%%%%%%%%%%%%%%%%%',\n",
       " '$vHIroyqx%%%%%%%%%%%%%%%%%%%%%%%%',\n",
       " '$nyEyCqwFcCqC%%%%%%%%%%%%%%%%%%%%',\n",
       " '$imury%%%%%%%%%%%%%%%%%%%%%%%%%%%']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_raw[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_chars = sorted(list(set(''.join(X_raw))))\n",
    "y_chars = sorted(list(set(''.join(y_raw))))\n",
    "\n",
    "xchar_indices = dict((c, i) for i, c in enumerate(X_chars))\n",
    "xindices_char = dict((i, c) for i, c in enumerate(X_chars))\n",
    "\n",
    "ychar_indices = dict((c, i) for i, c in enumerate(y_chars))\n",
    "yindices_char = dict((i, c) for i, c in enumerate(y_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(X_raw), MAX_WORD_LEN, len(X_chars)), dtype=np.bool)\n",
    "y = np.zeros((len(y_raw), MAX_PHONE_LEN, len(y_chars)), dtype=np.bool)\n",
    "\n",
    "for i, word in enumerate(X_raw):\n",
    "    for t, char in enumerate(word):\n",
    "        X[i, t, xchar_indices[char]] = 1\n",
    "\n",
    "for i, word in enumerate(y_raw):\n",
    "    for t, char in enumerate(word):\n",
    "        y[i, t, ychar_indices[char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        ..., \n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        ..., \n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        ..., \n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       ..., \n",
       "       [[False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        ..., \n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        ..., \n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "\n",
       "       [[False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        [False, False,  True, ..., False, False, False],\n",
       "        ..., \n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]], dtype=bool)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((106422, 35, 53), (106422, 34, 41))\n",
      "Compiling the model ...\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "max_len = X.shape[1]\n",
    "n_feats = X.shape[2]\n",
    "n_outs = y.shape[2]\n",
    "n_hidden = 32\n",
    " \n",
    "print(\"Compiling the model ...\")\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0., input_shape=(max_len, n_feats)),\n",
    "    LSTM(n_hidden, return_sequences=True),\n",
    "    LSTM(n_hidden, return_sequences=True),\n",
    "    LSTM(n_hidden, return_sequences=True),\n",
    "    TimeDistributed(Dense(n_outs, activation='softmax')),\n",
    "])\n",
    "optimizer = RMSprop(lr=0.001, decay=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Training the model ...\")\n",
    "hist = model.fit(X, y, batch_size=16, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model ...\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 58s - loss: 1.2371    \n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 57s - loss: 1.2374    \n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 50s - loss: 1.2379    \n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 56s - loss: 1.2350    \n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 57s - loss: 1.2366    \n"
     ]
    }
   ],
   "source": [
    "print(\"Training the model ...\")\n",
    "hist = model.fit(X, y, batch_size=5, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model ...\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 289s - loss: 1.2475   \n"
     ]
    }
   ],
   "source": [
    "print(\"Training the model ...\")\n",
    "hist = model.fit(X, y, batch_size=1, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### getting first results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=0.5):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    #probas = np.random.multinomial(1, preds, 1)\n",
    "    return yindices_char[np.argmax(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's try\n",
      "@RADY#############\n",
      "$KRNAH%%%%%%%%%%%%%%\n"
     ]
    }
   ],
   "source": [
    "def ydec(s):\n",
    "    res = ''\n",
    "    for t, char in enumerate(s):\n",
    "        if char != '$' and char != '%':\n",
    "            res += phoneme_dec[char]\n",
    "        else:\n",
    "            res += char\n",
    "    return res\n",
    "    \n",
    "word = X_raw[10]\n",
    "print(\"Let's try\")\n",
    "print(word[::-1])\n",
    "x = np.zeros((1, MAX_WORD_LEN, len(X_chars)))\n",
    "for t, char in enumerate(word):\n",
    "    #print char\n",
    "    x[0, t, xchar_indices[char]] = 1.\n",
    "#print x\n",
    "\n",
    "preds = model.predict(x, verbose=0)[0]\n",
    "print ydec(''.join(map(sample, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''train = aux.read_train('train.csv', nlines=1000)\n",
    "### Approach 1. Joint encoder-decoder\n",
    "print(\"Creating train data ...\")\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "max_len = X.shape[1]\n",
    "n_feats = X.shape[2]\n",
    "n_outs = y.shape[2] # In fact it equals X.shape[2]\n",
    "n_hidden = 32\n",
    " \n",
    "print(\"Compiling the model ...\")\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0., input_shape=(max_len, n_feats)),\n",
    "    LSTM(n_hidden, return_sequences=True),\n",
    "    LSTM(n_hidden, return_sequences=True),\n",
    "    LSTM(n_hidden, return_sequences=True),\n",
    "    TimeDistributed(Dense(n_outs, activation='softmax')),\n",
    "])\n",
    "optimizer = RMSprop(lr=0.001, decay=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    " \n",
    "print(\"Training the model ...\")\n",
    "hist = model.fit(X, y, batch_size=16, nb_epoch=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
